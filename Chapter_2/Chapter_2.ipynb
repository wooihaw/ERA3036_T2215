{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/wooihaw/ERA3036_T2215/blob/main/Chapter_2/Chapter_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table of Contents\n",
    "* [Loading Data](#loading-data)\n",
    "* [Statistical Summary and Class Breakdown](#statistical-summary)\n",
    "* [Dropping Rows with Missing Values](#dropping-rows)\n",
    "* [Data Imputation](#data-imputation)\n",
    "* [Min-max Scaling](#min-max-scaling)\n",
    "* [standardization](#standardization)\n",
    "* [Robust Scaling](#robust-scaling)\n",
    "* [Categorical Data](#categorical-data)\n",
    "* [Feature Engineering](#feature-engineering)\n",
    "* [Univariate Selection](#univariate-selection)\n",
    "* [Model-based Selection](#model-selection)\n",
    "* [Recursive Feature Elimination](#recursive-feature-elimination)\n",
    "* [Dimensionality Reduction](#dimensionality-reduction)\n",
    "* [Hold-out Validation](#hold-out-validation)\n",
    "* [Cross Validation](#cross-validation)\n",
    "* [Confusion Matrix](#confusion-matrix)\n",
    "* [Classification Report](#classification-report)\n",
    "* [Grid Search](#grid-search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialization\n",
    "%matplotlib inline\n",
    "from warnings import filterwarnings\n",
    "filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Data <a class=\"anchor\" id=\"loading-data\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data from CSV file\n",
    "from pandas import read_csv\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "names = ['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age', 'class']\n",
    "df = read_csv('../data/pima-indians-diabetes.data.csv', names=names)\n",
    "array = df.values\n",
    "# separate data into features and targets\n",
    "X = array[:,0:8]\n",
    "y = array[:,8]\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Statistical Summary and Class Breakdown <a class=\"anchor\" id=\"statistical-summary\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Print statistical summary and class breakdown\n",
    "from pandas import read_csv\n",
    "names = ['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age', 'class']\n",
    "df = read_csv('../data/pima-indians-diabetes.data.csv', names=names)\n",
    "print(df.shape) # print the dimension of the data\n",
    "print(df.describe()) # print the statistical summary of the data\n",
    "class_counts = df.groupby('class').size()\n",
    "print(class_counts) # print the class breakdown of the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dropping Rows with Missing Values <a class=\"anchor\" id=\"dropping-rows\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handling missing values by dropping data samples with missing values\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "df = pd.DataFrame({'Age': [17, 23, 'x', 38, 54, 67, 32],\n",
    "                  'Height': [160, 172, 150, 165, 163, 158, 175],\n",
    "                  'Weight':[50, 68, 43, 52, 47, 49, 'x']})\n",
    "df.replace({'x': np.nan}, inplace=True) # replace missing values (x) with NaN\n",
    "print(df)\n",
    "print(df.isnull().sum())  # show the number of NaN in each column\n",
    "df.dropna(inplace=True)  # drop rows with NaN\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Imputation <a class=\"anchor\" id=\"data-imputation\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Handling missing values by imputing missing values with statistic\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "df = pd.DataFrame({'Age': [17, 23, 'x', 38, 54, 67, 32],\n",
    "                  'Height': [160, 172, 150, 165, 163, 158, 175],\n",
    "                  'Weight':[50, 68, 43, 52, 47, 49, 'x']})\n",
    "df.replace({'x': np.nan}, inplace=True)\n",
    "print(df)\n",
    "df['Age'].fillna(df['Age'].median(), inplace=True) # replace NaN with median\n",
    "df['Weight'].fillna(df['Weight'].mean(), inplace=True) # replace NaN with mean\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Categorical Data <a class=\"anchor\" id=\"categorical-data\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handling categorical data\n",
    "import pandas as pd\n",
    "df0 = pd.DataFrame({'year':[2015, 2017, 2013, 2018, 2020], \n",
    "                  'make':['Toyota', 'Honda', 'Perodua', 'Hyundai', 'Toyota'],\n",
    "                  'engine':[1.5, 1.8, 1.3, 1.6, 1.8],\n",
    "                  'review':['moderate', 'good', 'poor', 'moderate', 'good']})\n",
    "mapping = {'poor':1, 'moderate':2, 'good':3}\n",
    "df0['review'] = df0['review'].map(mapping) # encode ordinal data\n",
    "df0 = pd.get_dummies(df0) # encode nominal data\n",
    "print(df0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Min-max Scaling <a class=\"anchor\" id=\"min-max-scaling\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale data (between 0 and 1)\n",
    "import numpy as np\n",
    "from pandas import read_csv\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "names = ['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age', 'class']\n",
    "df = read_csv('../data/pima-indians-diabetes.data.csv', names=names)\n",
    "array = df.values\n",
    "# separate array into input and output components\n",
    "X = array[:,:-1]\n",
    "y = array[:,-1]\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "scaler.fit(X)\n",
    "scaledX = scaler.transform(X)\n",
    "# Check min and max of all columns\n",
    "print(f'minimum={np.min(scaledX, axis=0)}, maximum={np.max(scaledX, axis=0)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standardization <a class=\"anchor\" id=\"standardization\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize data (0 mean, 1 stdev)\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from pandas import read_csv\n",
    "names = ['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age', 'class']\n",
    "df = read_csv('../data/pima-indians-diabetes.data.csv', names=names)\n",
    "array = df.values\n",
    "# separate array into input and output components\n",
    "X = array[:,:-1]\n",
    "y = array[:,-1]\n",
    "scaler = StandardScaler()\n",
    "scaledX = scaler.fit_transform(X)\n",
    "# Check mean and standard deviation of all columns\n",
    "print(f'mean={np.mean(scaledX, axis=0)}, variance={np.var(scaledX, axis=0)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Robust Scaling <a class=\"anchor\" id=\"robust-scaling\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Robust scaling (0 median, 1 IQR)\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from pandas import read_csv\n",
    "names = ['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age', 'class']\n",
    "df = read_csv('../data/pima-indians-diabetes.data.csv', names=names)\n",
    "array = df.values\n",
    "# separate array into input and output components\n",
    "X = array[:, :-1]\n",
    "y = array[:, -1]\n",
    "scaler = RobustScaler()\n",
    "scaledX = scaler.fit_transform(X)\n",
    "# Check median and IQR of all columns\n",
    "q3, q1 = np.percentile(scaledX, [75 ,25], axis=0)\n",
    "print(f'median={np.median(scaledX, axis=0)}, IQR={q3-q1}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering <a class=\"anchor\" id=\"feature-engineering\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Create 2 new features\n",
    "from pandas import read_csv\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "names = ['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age', 'class']\n",
    "df = read_csv('../data/pima-indians-diabetes.data.csv', names=names)\n",
    "win_size = 3\n",
    "df['plas_pres'] = df['plas'] + df['pres'] # new feature 1\n",
    "df['mass_ave'] = df['mass'].rolling(win_size).mean() # new feature 2\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Univariate Selection <a class=\"anchor\" id=\"univariate-selection\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Selection with Univariate Selection\n",
    "from pandas import read_csv\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "# load data\n",
    "names = ['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age', 'class']\n",
    "df = read_csv('../data/pima-indians-diabetes.data.csv', names=names)\n",
    "array = df.values\n",
    "X = array[:, :-1]\n",
    "y = array[:, -1]\n",
    "selector = SelectKBest(k=4)\n",
    "features = selector.fit_transform(X, y)\n",
    "selected = selector.get_support()\n",
    "# Show selected features\n",
    "print([names[i] for i in range(len(names)-1) if selected[i]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model-based Selection <a class=\"anchor\" id=\"model-selection\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model-based Feature Selection with Random Forest\n",
    "from pandas import read_csv\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "names = ['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age', 'class']\n",
    "df = read_csv('../data/pima-indians-diabetes.data.csv', names=names)\n",
    "array = df.values\n",
    "X = array[:, :-1]\n",
    "y = array[:, -1]\n",
    "selector = SelectFromModel(RandomForestClassifier(), threshold='median')\n",
    "features = selector.fit_transform(X, y)\n",
    "selected = selector.get_support()\n",
    "# Show selected features\n",
    "print([names[i] for i in range(len(names)-1) if selected[i]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recursive Feature Elimination <a class=\"anchor\" id=\"recursive-feature-elimination\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Feature Selection with RFE\n",
    "from pandas import read_csv\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "filename = '../data/pima-indians-diabetes.data.csv'\n",
    "names = ['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age', 'class']\n",
    "df = read_csv(filename, names=names)\n",
    "array = df.values\n",
    "X = array[:, :-1]\n",
    "y = array[:, -1]\n",
    "model = DecisionTreeClassifier()\n",
    "rfe = RFE(model, n_features_to_select=4)\n",
    "features = rfe.fit_transform(X, y)\n",
    "selected = rfe.get_support()\n",
    "# Show selected features\n",
    "print([names[i] for i in range(len(names)-1) if selected[i]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dimensionality Reduction <a class=\"anchor\" id=\"dimensionality-reduction\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dimensionality Reduction with PCA\n",
    "from pandas import read_csv\n",
    "from sklearn.decomposition import PCA\n",
    "names = ['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age', 'class']\n",
    "df = read_csv('../data/pima-indians-diabetes.data.csv', names=names)\n",
    "array = df.values\n",
    "X = array[:, :-1]\n",
    "y = array[:, -1]\n",
    "pca = PCA(n_components=3)\n",
    "features = pca.fit_transform(X)\n",
    "# summarize components\n",
    "print(f\"Explained Variance: {pca.explained_variance_ratio_}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hold-out Validation <a class=\"anchor\" id=\"hold-out-validation\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate using a train and a test set\n",
    "from pandas import read_csv\n",
    "from sklearn.model_selection import train_test_split as split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "names = ['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age', 'class']\n",
    "df = read_csv('../data/pima-indians-diabetes.data.csv', names=names)\n",
    "array = df.values\n",
    "X = array[:, :-1]\n",
    "y = array[:, -1]\n",
    "X_train, X_test, y_train, y_test = split(X, y, test_size=0.33, random_state=42)\n",
    "model = KNeighborsClassifier()\n",
    "model.fit(X_train, y_train)\n",
    "result = model.score(X_test, y_test)\n",
    "print(f\"Accuracy: {result:.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross Validation <a class=\"anchor\" id=\"cross-validation\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Evaluate using Cross Validation\n",
    "from pandas import read_csv\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "names = ['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age', 'class']\n",
    "df = read_csv('../data/pima-indians-diabetes.data.csv', names=names)\n",
    "array = df.values\n",
    "X = array[:, :-1]\n",
    "y = array[:, -1]\n",
    "model = KNeighborsClassifier()\n",
    "kfold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "results = cross_val_score(model, X, y, cv=kfold)\n",
    "print(f\"Accuracy: {results.mean():.2%} ({results.std():.2%})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confusion Matrix <a class=\"anchor\" id=\"confusion-matrix\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Plot Confusion Matrix\n",
    "from pandas import read_csv\n",
    "from sklearn.model_selection import train_test_split as split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "names = ['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age', 'class']\n",
    "df = read_csv('../data/pima-indians-diabetes.data.csv', names=names)\n",
    "array = df.values\n",
    "X = array[:, :-1]\n",
    "y = array[:, -1]\n",
    "X_train, X_test, y_train, y_test = split(X, y, test_size=0.33, random_state=42)\n",
    "model = KNeighborsClassifier()\n",
    "model.fit(X_train, y_train)\n",
    "ConfusionMatrixDisplay.from_estimator(model, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification Report <a class=\"anchor\" id=\"classification-report\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Classification report\n",
    "from pandas import read_csv\n",
    "from sklearn.model_selection import train_test_split as split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from yellowbrick.classifier import ClassificationReport\n",
    "names = ['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age', 'class']\n",
    "df = read_csv('../data/pima-indians-diabetes.data.csv', names=names)\n",
    "array = df.values\n",
    "X = array[:, :-1]\n",
    "y = array[:, -1]\n",
    "X_train, X_test, y_train, y_test = split(X, y, test_size=0.33, random_state=42)\n",
    "model = KNeighborsClassifier()\n",
    "model.fit(X_train, y_train)\n",
    "report = ClassificationReport(model)\n",
    "report.fit(X_train, y_train)\n",
    "report.score(X_test, y_test)\n",
    "report.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid Search <a class=\"anchor\" id=\"grid-search\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter tuning with grid search\n",
    "from pandas import read_csv\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split as split, KFold\n",
    "names = ['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age', 'class']\n",
    "df = read_csv('../data/pima-indians-diabetes.data.csv', names=names)\n",
    "X = df.values[:, :-1]\n",
    "y = df.values[:, -1]\n",
    "X_train, X_test, y_train, y_test = split(X, y, random_state=42)\n",
    "model = DecisionTreeClassifier(random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "print(f'Accuracy without tuning: {model.score(X_test, y_test):.2%}')\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "params = dict(criterion=['gini', 'entropy'], max_leaf_nodes=range(2, 21))\n",
    "grid = GridSearchCV(model, params, cv=kf, n_jobs=-1, verbose=2)\n",
    "grid.fit(X_train, y_train)\n",
    "print(grid.best_params_)\n",
    "model.set_params(**grid.best_params_).fit(X_train, y_train)\n",
    "print(f'Accuracy with tuning: {model.score(X_test, y_test):.2%}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
